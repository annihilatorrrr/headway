#!/bin/bash -e

function usage() {
  cat << EOF
usage: $0 <build-dir>
examples:
    $0 planet
    $0 seattle

Use an upload prefix other than what's in bin/_headway_version.sh
    HEADWAY_DATA_TAG=dev $0 planet
    HEADWAY_DATA_TAG=dev $0 seattle
EOF
}

if [ ! $# -eq 1 ]; then
  usage
  exit 1
fi

REPO_ROOT=$(git rev-parse --show-toplevel)
DATA_ROOT="${REPO_ROOT}/data"

upload_pids=()
function kill_uploads() {
  echo "Killing any in-progress uploads before exiting"
  for pid in ${upload_pids[*]}; do
    kill "${pid[*]}"
  done
}

trap kill_uploads EXIT

function upload() {
  INPUT_GLOB=$1
  OUTPUT_PREFIX=$2

  INPUT_PATH_GLOB="${DATA_ROOT}/${INPUT_GLOB}"
  if ! ls $INPUT_PATH_GLOB 1> /dev/null 2>&1; then
    echo "target file doesn't exist: '${INPUT_PATH_GLOB}'"
    exit 1
  fi

  for INPUT_PATH in $INPUT_PATH_GLOB; do
    RESOURCE="${OUTPUT_PREFIX}/$(basename "$INPUT_PATH")"
    BUCKET=$HEADWAY_S3_BUCKET
    # I'm seeing much faster uploads with the openstack swift client vs the aws cli
    # Plus, my host seems to be pretty flaky with large uploads via the `aws s3` cli.
    #
    # Note you'll need to be authenticated to run this.
    #   e.g. (source ~/openrc.sh && bin/publish-data)
    echo "Uploading ${INPUT_PATH} -> s3://${BUCKET}/${RESOURCE}"
    swift upload --segment-size=5G --skip-identical "$BUCKET" "$INPUT_PATH" --object-name="$RESOURCE" & upload_pids+=($!)
  done
}

source "${REPO_ROOT}/.env"

# stash env vars in local before they get clobbered by _headway_version.sh
local_data_tag=$HEADWAY_DATA_TAG
source "${REPO_ROOT}/bin/_headway_version.sh"

if [ ! -z "$HEADWAY_TAG" ]; then
  HEADWAY_DATA_TAG="$HEADWAY_TAG"
fi

export HEADWAY_DATA_TAG="${local_data_tag:-$HEADWAY_DATA_TAG}"

DEPLOYMENT_ENV_FILE="${REPO_ROOT}/builds/$1/env.sh"
if [ ! -f "$DEPLOYMENT_ENV_FILE" ]; then
    echo "missing file ${DEPLOYMENT_ENV_FILE}"
    exit 1
fi
source "$DEPLOYMENT_ENV_FILE"

set -o nounset

upload "${HEADWAY_AREA}.valhalla.tar.zst"      "${HEADWAY_DATA_TAG}/${HEADWAY_AREA_TAG}"
upload "${HEADWAY_AREA}.elasticsearch.tar.zst" "${HEADWAY_DATA_TAG}/${HEADWAY_AREA_TAG}"
upload "${HEADWAY_AREA}.mbtiles"               "${HEADWAY_DATA_TAG}/${HEADWAY_AREA_TAG}"
upload "${HEADWAY_AREA}.placeholder.tar.zst"   "${HEADWAY_DATA_TAG}/${HEADWAY_AREA_TAG}"
upload "${HEADWAY_AREA}.osm.pbf"               "${HEADWAY_DATA_TAG}/${HEADWAY_AREA_TAG}"

# Upload transit
upload "${HEADWAY_AREA}*.graph.obj.zst" "${HEADWAY_DATA_TAG}/${HEADWAY_AREA_TAG}"
upload "${HEADWAY_AREA}*.gtfs.tar.zst"  "${HEADWAY_DATA_TAG}/${HEADWAY_AREA_TAG}"

# These files are generic across all areas
upload terrain.mbtiles "${HEADWAY_DATA_TAG}"
upload landcover.mbtiles "${HEADWAY_DATA_TAG}"

rets=()
for pid in ${upload_pids[*]}; do
  wait $pid
  status=$?
  rets+=($status)
  if [ ! $status ]; then
    echo "error in upload"
    exit $status
  fi
done

echo "Return codes: ${rets[*]}"
